{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'cPickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e798043728cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'cPickle'"
     ]
    }
   ],
   "source": [
    "# # BCM Rule - recurrent network\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as sig\n",
    "get_ipython().magic('matplotlib inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NeuralNet(object):\n",
    "    \n",
    "    def __init__(self, GROUPS_NUM=5, FF_NUM=200, REC_EXC_NUM=100, REC_INH_NUM=100, \n",
    "                 TOT_TIME=20, STEPS_DIM=0.0001,  TIME_CONST = 0.01,\n",
    "                 TARGET_RATE=20, STARTING_RATE = 20, MEAN_DRIVE = 10,\n",
    "                 THETA_START=0.07, ETA_E=float('1e-6'), ETA_I=float('1e-4'), TAU=1,\n",
    "                 FF_PL=False, REC_PL_E=False, REC_PL_I=False):\n",
    "        \n",
    "        #self.GROUPS_NUM = GROUPS_NUM\n",
    "            \n",
    "        self.FF_NUM = FF_NUM\n",
    "        self.REC_EXC_NUM = REC_EXC_NUM\n",
    "        self.REC_INH_NUM = REC_INH_NUM\n",
    "        self.REC_NUM = REC_EXC_NUM + REC_INH_NUM        \n",
    "        self.TOT_TIME = TOT_TIME\n",
    "        self.STEPS_DIM = STEPS_DIM\n",
    "        self.STARTING_RATE = STARTING_RATE #starting rate for recurrent network\n",
    "        self.TARGET_RATE = TARGET_RATE\n",
    "        self.THETA_START = THETA_START\n",
    "        self.ETA_E = ETA_E\n",
    "        self.ETA_I = ETA_I\n",
    "        self.TAU = TAU #for weights\n",
    "        self.FF_PL = FF_PL\n",
    "        self.REC_PL_E = REC_PL_E\n",
    "        self.REC_PL_I = REC_PL_I\n",
    "        self.TIME_CONST = TIME_CONST #for rate\n",
    "        self.MEAN_DRIVE = MEAN_DRIVE\n",
    "        \n",
    "        self.SUB_SAMP = 2000\n",
    "        \n",
    "        self.change_values()\n",
    "        self.set_ff_activation()\n",
    "        \n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '''%d FF neurons\\n%d REC neurons''' % (self.FF_NUM, self.REC_NUM) \n",
    "        \n",
    "        \n",
    "    def change_values(self):\n",
    "        \n",
    "        self.STEPS_N = round(self.TOT_TIME/self.STEPS_DIM) # time steps = total simulation time / simulation step size\n",
    "        self.time_vect = np.linspace(0,self.TOT_TIME, self.STEPS_N) # create a time vector of size TOT.time and step size \n",
    "        \n",
    "        self.rec_nn = np.zeros((self.REC_NUM, self.STEPS_N)) # create empty array with size of the recurrent network\n",
    "        self.rec_nn[:,0] = np.random.randint(0,self.STARTING_RATE,self.REC_NUM) # intial firing rates at time step 0\n",
    "        \n",
    "        self.ff_nn = np.zeros((self.REC_NUM, self.STEPS_N))\n",
    "        \n",
    "        # create a random weight matrix for feed-forward input (size REC x FF) \n",
    "        self.w_ff = np.eye(self.REC_NUM)\n",
    "        \n",
    "        self.w_ff[self.REC_EXC_NUM:,self.REC_EXC_NUM:] = 0 #no feedforward input for inhibitory neurons! \n",
    "        \n",
    "        # create a random weight matrix for the recurrent network\n",
    "        \n",
    "        #Draw recurrent weights from gamma distribution\n",
    "        R = 0.1 #Limit radius for eigenvalues in complex space\n",
    "        K = 2 #shape of the Gamma distribution\n",
    "        THETA = R/((2*self.REC_NUM)**(1/2.0))\n",
    "\n",
    "        w_rec = np.random.gamma(K, THETA, [self.REC_NUM,self.REC_NUM])\n",
    "        np.fill_diagonal(w_rec,0)\n",
    "        scal = np.absolute(sum(w_rec[:,:self.REC_EXC_NUM].T)/sum(w_rec[:,self.REC_EXC_NUM:].T))        \n",
    "        w_rec[:,self.REC_EXC_NUM:] = -(w_rec[:,self.REC_EXC_NUM:] * scal.reshape((-1,1))) #inhibitory \n",
    "        \n",
    "#        w_rec[:,self.REC_EXC_NUM:] = -3*w_rec[:,self.REC_EXC_NUM:] #inhibition 3x excitation\n",
    "        \n",
    "        self.w_rec = w_rec\n",
    "\n",
    "        self.w_history = np.zeros((\n",
    "                self.REC_NUM, self.REC_NUM, round(self.STEPS_N/self.SUB_SAMP-1)))\n",
    "        \n",
    "        self.theta = np.zeros((self.REC_NUM, self.STEPS_N))\n",
    "        self.theta[:,0] = self.THETA_START\n",
    "        \n",
    "        #targ = np.ones((self.REC_NUM))*self.TARGET_RATE\n",
    "        #self.mean_drive = targ - self.w_rec.dot(targ)\n",
    "    \n",
    "    def set_ff_activation(self, BACKGROUND_TYPE='none', #BACKGROUND_VALUE=None, \n",
    "                          STIM_VALUE=1, STIM_TYPE='none', CORR_IN_GROUP=0.5,#STIM_LENGTH=None, #STIM_END=None,\n",
    "                          GROUPS_NUM=5, make_uncorr=False):\n",
    "                        #target_neurons=[]):\n",
    "        \n",
    "        if STIM_VALUE is None:\n",
    "            STIM_VALUE = self.STARTING_RATE/4\n",
    "        \n",
    "        #Set the background (input values to nonstimulated neurons - zero or random noise)\n",
    "        if BACKGROUND_TYPE=='none':\n",
    "            #Set the input values of the non stimulated neurons\n",
    "            noise = np.zeros((self.REC_NUM, self.STEPS_N)) \n",
    "            \n",
    "        elif BACKGROUND_TYPE=='random':\n",
    "            #Set the input values of the non stimulated neurons\n",
    "            noise = np.random.rand(\n",
    "                self.REC_NUM, self.time_vect.shape[0])*NOISE_VALUE \n",
    "            \n",
    "        elif BACKGROUND_TYPE=='OU_noise':\n",
    "            sigma_mtx = corr_mtx_4_ou(N=self.FF_NUM, VAR=STIM_VALUE, GROUPS_NUM=GROUPS_NUM, \n",
    "                  CORR_IN_GROUP=CORR_IN_GROUP, make_uncorr=make_uncorr, ei_clustering=False)\n",
    "            \n",
    "            noise = ou_process(sigma_mtx, self.STEPS_N, STEPS_DIM=self.STEPS_DIM)\n",
    "            \n",
    "            plt.imshow(sigma_mtx)\n",
    "        \n",
    "        elif BACKGROUND_TYPE=='OU_noise_ei_clustering':\n",
    "            sigma_mtx = corr_mtx_4_ou(N=self.FF_NUM, VAR=STIM_VALUE, GROUPS_NUM=GROUPS_NUM, \n",
    "                  CORR_IN_GROUP=CORR_IN_GROUP, make_uncorr=make_uncorr, ei_clustering=True)\n",
    "                \n",
    "            plt.imshow(sigma_mtx)\n",
    "            \n",
    "            noise = ou_process(sigma_mtx, self.STEPS_N, STEPS_DIM=self.STEPS_DIM)\n",
    "            \n",
    "        self.ff_nn = noise\n",
    "\n",
    "        \n",
    "    def display_stim(self):\n",
    "        f, ax = plt.subplots(1,1, figsize = (20,5))\n",
    "        ax.imshow(self.ff_nn, aspect='auto',  interpolation='nearest')\n",
    "        plt.colorbar\n",
    "        \n",
    "    \n",
    "    def run_network(self):\n",
    "        \n",
    "        #  rec.nn                           --> recurrent network \n",
    "        #  STEPS_DIM/TIME_CONST             --> size of simulation interval / rate time constant\n",
    "        #  self.rec_nn                     --> leaky term \n",
    "        #  w_rec dot rec_nn                --> matrix multiplication of recurrent weight matrix and recurrent \n",
    "        #  w_ff dot ff_nn                  --> feed-forward weight matrix * feed-forward input firing rates\n",
    "        #self.w_history[:,:,0] = self.w_rec\n",
    "        k=0\n",
    "        \n",
    "        for i in range(1,self.STEPS_N):\n",
    "            self.rec_nn[:,i] = self.rec_nn[:,i-1] + (self.STEPS_DIM/self.TIME_CONST)*(\n",
    "                    -self.rec_nn[:,i-1] + io_function(self.w_rec[:,:].dot(self.rec_nn[:,i-1]) + \n",
    "                    self.w_ff[:,:].dot(self.ff_nn[:,i-1]) + self.MEAN_DRIVE))\n",
    "            \n",
    "            # BCM threshold theta\n",
    "            # TAU --> BCM time constant\n",
    "\n",
    "            \n",
    "            # recurrent network placticiy\n",
    "            # ETA --> factor of the BCM rule\n",
    "\n",
    "            if i%500 == 0 and i > (5*self.TAU/self.STEPS_DIM):\n",
    "                if self.REC_PL_E:\n",
    "                    self.w_rec[:,:self.REC_EXC_NUM] = self.w_rec[:,:self.REC_EXC_NUM] + self.ETA_E*np.outer(\n",
    "                        (self.rec_nn[:,i-1]*(self.rec_nn[:,i-1] - self.theta[:,i-1])), \n",
    "                        (self.rec_nn[:self.REC_EXC_NUM,i-1]))\n",
    "                    \n",
    "                if self.REC_PL_I:\n",
    "                    self.w_rec[:,self.REC_EXC_NUM:] = self.w_rec[:,self.REC_EXC_NUM:] - self.ETA_I*np.outer(\n",
    "                        (self.rec_nn[:,i-1] - self.TARGET_RATE), \n",
    "                        self.rec_nn[self.REC_EXC_NUM:,i-1])\n",
    "                    \n",
    "                if self.FF_PL:                \n",
    "                    self.w_ff = self.w_ff + self.ETA *(\n",
    "                        (self.rec_nn[:,i-1]*(self.rec_nn[:,i-1] - self.theta[:,i-1])) * self.ff_nn[:,i-1].T)\n",
    "\n",
    "                \n",
    "                np.fill_diagonal(self.w_rec[:,:], 0) # set diagonal to 0 to prevent self-excitation\n",
    "                \n",
    "\n",
    "            self.w_rec[:,:self.REC_EXC_NUM] = np.clip(self.w_rec[:,:self.REC_EXC_NUM], 0, np.inf)\n",
    "            self.w_rec[:,self.REC_EXC_NUM:] = np.clip(self.w_rec[:,self.REC_EXC_NUM:], -np.inf,0)\n",
    "                \n",
    "            self.theta[:,i] = self.theta[:,i-1] + (self.STEPS_DIM/self.TAU) * (\n",
    "                -self.theta[:,i-1] + (self.rec_nn[:,i]**2)/self.TARGET_RATE)\n",
    "            \n",
    "            if i%self.SUB_SAMP == 0:\n",
    "                self.w_history[:,:,k] = self.w_rec[:,:]\n",
    "                k+=1\n",
    "            \n",
    "        self.w_history[:,:,-1] = self.w_rec\n",
    "            \n",
    "                                \n",
    "    def plot_rate(self):\n",
    "        f, ax = plt.subplots(1,2, figsize = (20,5))\n",
    "\n",
    "        img1 = ax[0].imshow(self.rec_nn[:,::1000], aspect='auto', interpolation = 'nearest')\n",
    "        ax[0].set_title('change in network firing rate over time')\n",
    "        plt.colorbar(img1, ax=ax[0])\n",
    "        \n",
    "        ax[1].plot(np.mean(self.rec_nn[:,:],0)) #mean rate over time over network \n",
    "        ax[1].set_title('mean change in rate of whole network over simulation')\n",
    "        \n",
    "    \n",
    "    def plot_weight(self):\n",
    "        f, ax = plt.subplots(1,2, figsize = (20,5))\n",
    "        ax[0].set_title('change in weights of subset of exc and inh neurons over simulation')\n",
    "        img1 = ax[0].pcolor(self.w_sample[:,::100], vmin=-4, vmax=4)\n",
    "        plt.colorbar(img1, ax=ax[0])\n",
    "        #plt.show()\n",
    "        \n",
    "        img2 = ax[1].imshow(self.w_history[:,:,0], interpolation='nearest')\n",
    "        ax[1].set_title('weight matrix at beginning of the simulation')\n",
    "        plt.colorbar(img2, ax=ax[1])\n",
    "\n",
    "\n",
    "def corr_mtx_4_ou(N, VAR=1, GROUPS_NUM=1, CORR_IN_GROUP=0.5,\n",
    "                   make_uncorr=False, ei_clustering=False):\n",
    "    \n",
    "    POS_CORR = CORR_IN_GROUP #positive correlation for inputs on covariance matrix\n",
    "    GROUP_SIZE = int(N/GROUPS_NUM) #number of neurons in each group \n",
    "\n",
    "    #Calculate the negative correlation to have 0.001 sum over the rows\n",
    "    if ei_clustering:\n",
    "        GROUP_SIZE = round(GROUP_SIZE/2)\n",
    "        NEG_CORR = -(0.999 + (GROUP_SIZE-1)*POS_CORR)/((GROUPS_NUM-1)*GROUP_SIZE)\n",
    "        block = POS_CORR*np.ones([GROUP_SIZE, GROUP_SIZE])\n",
    "        sigma_mtx = np.kron(np.eye(GROUPS_NUM), block) #block diagonal \n",
    "        sigma_noise = np.kron(np.ones((2,2)), sigma_mtx)\n",
    "        \n",
    "        np.fill_diagonal(sigma_noise, 1.001)\n",
    "    else:\n",
    "        NEG_CORR = -(0.999 + (GROUP_SIZE-1)*POS_CORR)/((GROUPS_NUM-1)*GROUP_SIZE)\n",
    "        block = POS_CORR*np.ones([GROUP_SIZE, GROUP_SIZE])\n",
    "        sigma_noise = np.kron(np.eye(GROUPS_NUM), block) #block diagonal \n",
    "        np.fill_diagonal(sigma_noise, 1)\n",
    "\n",
    "    if not make_uncorr:\n",
    "        sigma_noise[sigma_noise == 0] = NEG_CORR #fill everything else with -ve correlations \n",
    "    \n",
    "    sigma_noise *= VAR    \n",
    "    \n",
    "    return sigma_noise\n",
    "\n",
    "def ou_process(cov_mtx, STEPS_N, TAU=0.5, STEPS_DIM=0.0001):\n",
    "    N = cov_mtx.shape[0]\n",
    "    ell_noise = np.linalg.cholesky(cov_mtx)\n",
    "    z_noise = np.sqrt(2*STEPS_DIM/TAU)\n",
    "\n",
    "    noise = np.zeros((N,STEPS_N))\n",
    "    noise[:,0] = ell_noise.dot(np.random.normal(0,1,(N)))\n",
    "    \n",
    "    for i in range(1,STEPS_N):\n",
    "        noise[:,i] = (1 - STEPS_DIM/TAU)*noise[:,i-1] + z_noise*ell_noise.dot(np.random.normal(0,1,N))\n",
    "    return noise\n",
    "\n",
    "def io_function(x):\n",
    "    #Nonlinear function that rectifies under 0\n",
    "    x[x<0] = 0\n",
    "    x[x>=20] = 20+80*np.tanh((x[x>=20]-20)/80)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = NeuralNet(GROUPS_NUM = 1, FF_NUM = 200, REC_EXC_NUM = 100, REC_INH_NUM = 100, \n",
    "                TOT_TIME = 3000, STEPS_DIM = 0.001, TIME_CONST = 0.01, \n",
    "                TARGET_RATE = 20, STARTING_RATE = 10, MEAN_DRIVE = 10,\n",
    "                THETA_START = 0.1, ETA_E = float('1e-7'), ETA_I = float('1e-6'), TAU = 1, \n",
    "                FF_PL = False, REC_PL_E = True, REC_PL_I = True)\n",
    "\n",
    "net.set_ff_activation(BACKGROUND_TYPE='OU_noise',  \n",
    "                          STIM_VALUE=5, STIM_TYPE='none', CORR_IN_GROUP=0.8,\n",
    "                          GROUPS_NUM=200, make_uncorr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.run_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,2, figsize = (20,5))\n",
    "\n",
    "img1 = ax[0].imshow(net.rec_nn[:,::10000], aspect='auto', interpolation = 'nearest')\n",
    "ax[0].set_title('change in network firing rate over time')\n",
    "plt.colorbar(img1, ax=ax[0])\n",
    "\n",
    "#ax[1].plot(np.mean(net.rec_nn[:,:],0)) #mean rate over time over network \n",
    "ax[1].plot(net.rec_nn[1,::10000]) #mean rate over time over network \n",
    "\n",
    "ax[1].set_title('mean change in rate of whole network over simulation')\n",
    "#ax[1].set_xlim(0,100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(net.w_rec)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff_weight = (net.w_history[:,:,-1]-net.w_history[:,:,0])\n",
    "plt.imshow(diff_weight[:,:], interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('difference between first and last weight matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exc_str = net.w_history[:,:,0]\n",
    "exc_end = net.w_history[:,:,-1]\n",
    "diff_exc_weight = (exc_end-exc_str)/(exc_str+0.000000001)\n",
    "diff_exc_weight[diff_exc_weight>0.70] = 0.7\n",
    "\n",
    "plt.imshow(diff_exc_weight, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('Normalized difference')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cov_in = np.cov(net.ff_n[:net.REC_EXC_NUM,:net.REC_EXC_NUM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(cov_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ex_hist = net.w_history[:net.REC_EXC_NUM,:net.REC_EXC_NUM]\n",
    "w_trend = np.reshape(ex_hist,(ex_hist.shape[0]*ex_hist.shape[1], ex_hist.shape[2]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_derivative = np.absolute(w_trend[:,:-1]-w_trend[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.mean(w_trend,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.imshow(w_trend, aspect='auto')\n",
    "for i in range(100):\n",
    "    plt.plot(net.w_history[i,:]-net.w_history[i,1])\n",
    "#plt.xlim([0,30])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.max(np.max(net.w_history[:,:,-1],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fin_weights = net.w_history[:,:,-1]\n",
    "fin_weights[fin_weights>(2/3)*np.max(np.max(net.w_history[:,:,-1],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "disp_weights = exc_end\n",
    "low_lim = 0.01\n",
    "up_lim = 0.02\n",
    "disp_weights[disp_weights<low_lim] = low_lim\n",
    "disp_weights[disp_weights>up_lim] = up_lim\n",
    "plt.imshow(disp_weights)\n",
    "plt.colorbar()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exc_weights = net.w_history[:,:,-1]\n",
    "thr = 2/3\n",
    "#exc_weights = exc_weights[:net.REC_EXC_NUM,:net.REC_EXC_NUM]\n",
    "exc_diff = np.zeros(exc_weights.shape)\n",
    "exc_diff[exc_weights>(thr*np.max(exc_weights))] = 1\n",
    "exc_diff[exc_weights<(thr*np.max(exc_weights))] = 0\n",
    "overlap = (exc_diff == exc_diff.T) * exc_diff\n",
    "bidirectional_connections = np.argwhere(exc_diff != 0)\n",
    "plt.imshow(exc_diff, interpolation = 'nearest', cmap='hot')\n",
    "plt.title('\\n strong (>2/3 max weight) bidirectional connections \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bidirectional_weights = net.w_history[:,:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt('nocorr_exc_PL_inh_newPL_bidirectional_connections.txt', bidirectional_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate lyapunov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bdw = np.loadtxt('exc_PL_inh_newPL_bidirectional_connections.txt')\n",
    "lyapunov_input = bdw\n",
    "\n",
    "def calc_lyap(bdw)\n",
    "\n",
    "    identity_mat = np.eye(net.REC_EXC_NUM)\n",
    "    A = lyapunov_input - identity_mat\n",
    "    Eij = sp.linalg.solve_lyapunov(A, 2*identity_mat)\n",
    "    Cij = np.corrcoef(Eij)\n",
    "    return Cij\n",
    "\n",
    "plt.imshow(Cij, interpolation = 'nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#f = plt.figure(figsize=(20,10))\n",
    "plt.imshow(net.ff_nn[:,::2000],  interpolation = 'nearest', aspect='auto')\n",
    "plt.title('Input in time')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run protocol "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAEACAYAAABVmQgcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKBBEpI8CQUT6KBBEpM//A1xSl/ytDp6/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f211668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w_hist_list = []\n",
    "activity_list = []\n",
    "\n",
    "# ===== 1 =====\n",
    "# 20 min, exc plasticity, correlated input\n",
    "\n",
    "#Initialize network - only ex plasticity, 40 min, no input to I neurons\n",
    "net = NeuralNet(FF_NUM = 200, REC_EXC_NUM = 100, REC_INH_NUM = 100, \n",
    "                TOT_TIME = 1200, STEPS_DIM = 0.001, TIME_CONST = 0.01, \n",
    "                TARGET_RATE = 20, STARTING_RATE = 10, \n",
    "                THETA_START = 0.1, ETA_E = float('1e-7'), ETA_I = float('1e-6'), TAU = 1, \n",
    "                FF_PL = False, REC_PL_E = True, REC_PL_I = True)\n",
    "\n",
    "#Initialize correlated input\n",
    "net.set_ff_activation(BACKGROUND_TYPE='OU_noise',  \n",
    "                          STIM_VALUE=5, STIM_TYPE='none', CORR_IN_GROUP=0.8,\n",
    "                          GROUPS_NUM=10, make_uncorr=False)\n",
    "\n",
    "#run network and save connections and downsampled activity and w_history\n",
    "net.run_network()\n",
    "w_hist_list.append(net.w_history[:,:,::10]) \n",
    "activity_list.append(net.rec_nn[:,::100])\n",
    "print('RAN: 20 min, exc plasticity, correlated input')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# ===== 2 =====\n",
    "#20 min, no plasticity, initial weights, uncorr input\n",
    "\n",
    "#get previous initial weigths:\n",
    "net.w_rec = w_hist_list[0][:,:,0]\n",
    "\n",
    "#Switch off plasticity:\n",
    "net.REC_PL_E = False\n",
    "\n",
    "#set new uncorrelated input:\n",
    "net.set_ff_activation(BACKGROUND_TYPE='OU_noise',  \n",
    "                          STIM_VALUE=5, STIM_TYPE='none', CORR_IN_GROUP=0.8,\n",
    "                          GROUPS_NUM=200, make_uncorr=True)\n",
    "\n",
    "#run network and save connections and downsampled activity and w_history\n",
    "net.run_network()\n",
    "w_hist_list.append(net.w_history[:,:,::10])\n",
    "activity_list.append(net.rec_nn[:,::10])\n",
    "print('RAN: 20 min, no plasticity, initial weights, uncorr input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# ===== 3 =====\n",
    "#20 min, no plasticity, final weights, uncorr input (same as above)\n",
    "\n",
    "#get previous final weigths:\n",
    "net.w_rec = w_hist_list[0][:,:,-1] #is this the right index?? \n",
    "\n",
    "#run network and save connections and downsampled activity and w_history\n",
    "net.run_network()\n",
    "w_hist_list.append(net.w_history[:,:,::10])\n",
    "activity_list.append(net.rec_nn[:,::10])\n",
    "print('RAN: 20 min, no plasticity, final weights, uncorr input (same as above)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# ===== 4 =====\n",
    "#20 min, plasticity, final weights, uncorr input (same as above)\n",
    "net.REC_PL_E = True\n",
    "\n",
    "#run network and save connections and downsampled activity and w_history\n",
    "net.run_network()\n",
    "w_hist_list.append(net.w_history[:,:,::10])\n",
    "activity_list.append(net.rec_nn[:,::100])\n",
    "\n",
    "print('RAN: 20 min, plasticity, final weights, uncorr input (same as above)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"whistlist.npy\", w_hist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w_hist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
